{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eaa3cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'streamlit-env (Python 3.9.19)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n streamlit-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Updated function to generate synthetic employee data with 'Attrition' and 'EducationLevel'\n",
    "def generate_synthetic_data(n=50000):\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Risk distribution (30% low, 50% medium, 20% high risk)\n",
    "    risk_distribution = np.random.choice(\n",
    "        ['Low Risk', 'Medium Risk', 'High Risk'],\n",
    "        size=n,\n",
    "        p=[0.3, 0.5, 0.2]\n",
    "    )\n",
    "    \n",
    "    # Job Satisfaction (scale of 1-10) based on risk category\n",
    "    job_satisfaction = np.where(\n",
    "        risk_distribution == 'Low Risk', np.random.randint(8, 11, size=n),\n",
    "        np.where(risk_distribution == 'Medium Risk', np.random.randint(4, 8, size=n),\n",
    "                 np.random.randint(1, 4, size=n))\n",
    "    )\n",
    "    \n",
    "    # Engagement Score (scale of 0-100) based on risk category\n",
    "    engagement_score = np.where(\n",
    "        risk_distribution == 'Low Risk', np.random.randint(75, 101, size=n),\n",
    "        np.where(risk_distribution == 'Medium Risk', np.random.randint(40, 75, size=n),\n",
    "                 np.random.randint(0, 40, size=n))\n",
    "    )\n",
    "    \n",
    "    # Performance Rating (scale of 1-5) based on risk category\n",
    "    performance_rating = np.where(\n",
    "        risk_distribution == 'Low Risk', np.random.randint(4, 6, size=n),\n",
    "        np.where(risk_distribution == 'Medium Risk', np.random.randint(2, 4, size=n),\n",
    "                 np.random.randint(1, 2, size=n))\n",
    "    )\n",
    "    \n",
    "    # Work-Life Balance (scale of 1-5) based on risk category\n",
    "    work_life_balance = np.where(\n",
    "        risk_distribution == 'Low Risk', np.random.randint(4, 6, size=n),\n",
    "        np.where(risk_distribution == 'Medium Risk', np.random.randint(2, 4, size=n),\n",
    "                 np.random.randint(1, 2, size=n))\n",
    "    )\n",
    "    \n",
    "    # Overtime (Yes/No) based on risk category\n",
    "    overtime = np.where(\n",
    "        risk_distribution == 'High Risk', np.random.choice(['Yes'], size=n),\n",
    "        np.random.choice(['No', 'Yes'], size=n, p=[0.7, 0.3])\n",
    "    )\n",
    "    \n",
    "    # Education Level (High School, Bachelor's, Master's)\n",
    "    education_level = np.random.choice(['High School', \"Bachelor's\", \"Master's\"], size=n, p=[0.3, 0.5, 0.2])\n",
    "    \n",
    "    # Other features that aren't necessarily tied to risk levels\n",
    "    age = np.random.randint(22, 60, size=n)\n",
    "    gender = np.random.choice(['Male', 'Female'], size=n, p=[0.5, 0.5])\n",
    "    department = np.random.choice(['R&D', 'Sales', 'HR', 'Marketing', 'Finance'], size=n)\n",
    "    tenure = np.random.randint(1, 21, size=n)\n",
    "    job_role = np.random.choice(['Engineer', 'Manager', 'Technician', 'Analyst', 'Developer'], size=n)\n",
    "    salary = np.random.randint(40000, 120000, size=n)\n",
    "    distance_from_home = np.random.randint(1, 50, size=n)\n",
    "    training_hours = np.random.randint(10, 100, size=n)\n",
    "    \n",
    "    # Create 'Attrition' based on risk category: High Risk employees have a higher chance of leaving\n",
    "    attrition = np.where(risk_distribution == 'High Risk', 1, 0)\n",
    "    \n",
    "    # Combine all features into a DataFrame\n",
    "    data = pd.DataFrame({\n",
    "        'EmployeeID': [f'E{str(i).zfill(5)}' for i in range(1, n + 1)],\n",
    "        'Age': age,\n",
    "        'Gender': gender,\n",
    "        'Department': department,\n",
    "        'Tenure': tenure,\n",
    "        'JobRole': job_role,\n",
    "        'Salary': salary,\n",
    "        'JobSatisfaction': job_satisfaction,\n",
    "        'EngagementScore': engagement_score,\n",
    "        'PerformanceRating': performance_rating,\n",
    "        'WorkLifeBalance': work_life_balance,\n",
    "        'DistanceFromHome': distance_from_home,\n",
    "        'TrainingHours': training_hours,\n",
    "        'Overtime': overtime,  # Add Overtime column\n",
    "        'EducationLevel': education_level,  # Add EducationLevel column\n",
    "        'Risk Category': risk_distribution,\n",
    "        'Attrition': attrition  # Add Attrition column as the target variable\n",
    "    })\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Generate and save the updated synthetic data\n",
    "synthetic_data = generate_synthetic_data(n=50000)\n",
    "synthetic_data.to_csv('synthetic_employee_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab631ea",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f5bdbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cca92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Load your synthetic dataset here\n",
    "df = pd.read_csv(\"synthetic_employee_data.csv\")\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=[\"Attrition\", \"EmployeeID\"])\n",
    "y = df[\"Attrition\"]\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_features = [\"Gender\", \"Department\", \"JobRole\", \"Overtime\", \"EducationLevel\"]\n",
    "numerical_features = [\"Age\", \"Tenure\", \"Salary\", \"JobSatisfaction\", \"EngagementScore\", \n",
    "                      \"PerformanceRating\", \"DistanceFromHome\", \"TrainingHours\", \"WorkLifeBalance\"]\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numerical_features),\n",
    "        (\"cat\", OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the preprocessor to the training data and transform the features\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "# Train Random Forest with more estimators and reduced tree depth\n",
    "rf_model = RandomForestClassifier(n_estimators=200, max_depth=8, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Train AdaBoost with more estimators and a higher learning rate\n",
    "ada_model = AdaBoostClassifier(n_estimators=500, learning_rate=0.2, random_state=42)\n",
    "ada_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the models\n",
    "with open('rf_model.pkl', 'wb') as f:\n",
    "    pickle.dump(\"C:\\dev\\Employee-Attrition-Prediction-Model\\rf_model\", f)\n",
    "with open(\"C:\\dev\\Employee-Attrition-Prediction-Modelada_model.pkl\", 'wb') as f:\n",
    "    pickle.dump(ada_model, f)\n",
    "\n",
    "print(\"Models retrained and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eb1327",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)  # This will print all the columns in your dataset\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
